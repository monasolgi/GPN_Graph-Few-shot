{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPN_Graph-Few-shot_exec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZeZ+mS2vUwC6/2qbZKMMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monasolgi/GPN_Graph-Few-shot/blob/master/GPN_Graph_Few_shot_exec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY_CXlfgYCxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9c4f4fd-cc86-43c9-b65c-f2b1e3b30e39"
      },
      "source": [
        "!wget 'https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_electronics_network.txt?raw=true'\n",
        "!wget 'https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_eletronics_test.mat?raw=true'\n",
        "!wget 'https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_eletronics_train.mat?raw=true'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-16 10:00:36--  https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_electronics_network.txt?raw=true\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_electronics_network.txt [following]\n",
            "--2021-06-16 10:00:36--  https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_electronics_network.txt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_electronics_network.txt [following]\n",
            "--2021-06-16 10:00:37--  https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_electronics_network.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1086626 (1.0M) [text/plain]\n",
            "Saving to: ‘Amazon_electronics_network.txt?raw=true.2’\n",
            "\n",
            "Amazon_electronics_ 100%[===================>]   1.04M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-06-16 10:00:37 (23.4 MB/s) - ‘Amazon_electronics_network.txt?raw=true.2’ saved [1086626/1086626]\n",
            "\n",
            "--2021-06-16 10:00:37--  https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_eletronics_test.mat?raw=true\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_eletronics_test.mat [following]\n",
            "--2021-06-16 10:00:37--  https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_eletronics_test.mat\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_eletronics_test.mat [following]\n",
            "--2021-06-16 10:00:38--  https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_eletronics_test.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4971904 (4.7M) [application/octet-stream]\n",
            "Saving to: ‘Amazon_eletronics_test.mat?raw=true.2’\n",
            "\n",
            "Amazon_eletronics_t 100%[===================>]   4.74M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-06-16 10:00:38 (46.1 MB/s) - ‘Amazon_eletronics_test.mat?raw=true.2’ saved [4971904/4971904]\n",
            "\n",
            "--2021-06-16 10:00:38--  https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_eletronics_train.mat?raw=true\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_eletronics_train.mat [following]\n",
            "--2021-06-16 10:00:39--  https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_eletronics_train.mat\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_eletronics_train.mat [following]\n",
            "--2021-06-16 10:00:39--  https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_eletronics_train.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16218608 (15M) [application/octet-stream]\n",
            "Saving to: ‘Amazon_eletronics_train.mat?raw=true.2’\n",
            "\n",
            "Amazon_eletronics_t 100%[===================>]  15.47M  39.4MB/s    in 0.4s    \n",
            "\n",
            "2021-06-16 10:00:40 (39.4 MB/s) - ‘Amazon_eletronics_train.mat?raw=true.2’ saved [16218608/16218608]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg1LgMkYVAb-"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import scipy.io as sio\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "valid_num_dic = {'Amazon_clothing': 17, 'Amazon_eletronics': 36, 'dblp': 27}\n",
        "\n",
        "def load_data(dataset_source):\n",
        "    n1s = []\n",
        "    n2s = []\n",
        "    for line in open(\"/content/Amazon_electronics_network.txt?raw=true\"):\n",
        "        n1, n2 = line.strip().split('\\t')\n",
        "        n1s.append(int(n1))\n",
        "        n2s.append(int(n2))\n",
        "\n",
        "    num_nodes = max(max(n1s),max(n2s)) + 1\n",
        "    adj = sp.coo_matrix((np.ones(len(n1s)), (n1s, n2s)),\n",
        "                                 shape=(num_nodes, num_nodes))\n",
        "\n",
        "\n",
        "    data_train = sio.loadmat(\"/content/Amazon_eletronics_train.mat?raw=true\")\n",
        "    train_class = list(set(data_train[\"Label\"].reshape((1,len(data_train[\"Label\"])))[0]))\n",
        "    \n",
        "\n",
        "    data_test = sio.loadmat(\"/content/Amazon_eletronics_test.mat?raw=true\")\n",
        "    class_list_test = list(set(data_test[\"Label\"].reshape((1,len(data_test[\"Label\"])))[0]))\n",
        "\n",
        "\n",
        "    labels = np.zeros((num_nodes,1))\n",
        "    labels[data_train['Index']] = data_train[\"Label\"]\n",
        "    labels[data_test['Index']] = data_test[\"Label\"]\n",
        "\n",
        "    features = np.zeros((num_nodes,data_train[\"Attributes\"].shape[1]))\n",
        "    features[data_train['Index']] = data_train[\"Attributes\"].toarray()\n",
        "    features[data_test['Index']] = data_test[\"Attributes\"].toarray()\n",
        "\n",
        "    class_list = []\n",
        "    for cla in labels:\n",
        "        if cla[0] not in class_list:\n",
        "            class_list.append(cla[0])  # unsorted\n",
        "\n",
        "    id_by_class = {}\n",
        "    for i in class_list:\n",
        "        id_by_class[i] = []\n",
        "    for id, cla in enumerate(labels):\n",
        "        id_by_class[cla[0]].append(id)\n",
        "\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    labels = lb.fit_transform(labels)\n",
        "\n",
        "    degree = np.sum(adj, axis=1)\n",
        "    degree = torch.FloatTensor(degree)\n",
        "\n",
        "    adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "    features = torch.FloatTensor(features)\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "\n",
        "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "    \n",
        "    class_list_valid = random.sample(train_class, valid_num_dic[dataset_source])\n",
        "\n",
        "    class_list_train = list(set(train_class).difference(set(class_list_valid)))\n",
        "\n",
        "    return adj, features, labels, degree, class_list_train, class_list_valid, class_list_test, id_by_class \n",
        "\n",
        "\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "\n",
        "def normalize_adj(adj):\n",
        "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    rowsum = np.array(adj.sum(1))\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
        "\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "\n",
        "def f1(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    return f1\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "\n",
        "\n",
        "def task_generator(id_by_class, class_list, n_way, k_shot, m_query):\n",
        "\n",
        "    # sample class indices\n",
        "    class_selected = random.sample(class_list, n_way)\n",
        "    id_support = []\n",
        "    id_query = []\n",
        "    for cla in class_selected:\n",
        "        temp = random.sample(id_by_class[cla], k_shot + m_query)\n",
        "        id_support.extend(temp[:k_shot])\n",
        "        id_query.extend(temp[k_shot:])\n",
        "\n",
        "    return np.array(id_support), np.array(id_query), class_selected\n",
        "\n",
        "\n",
        "\n",
        "def euclidean_dist(x, y):\n",
        "    # x: N x D query\n",
        "    # y: M x D prototype\n",
        "    n = x.size(0)\n",
        "    m = y.size(0)\n",
        "    d = x.size(1)\n",
        "    assert d == y.size(1)\n",
        "\n",
        "    x = x.unsqueeze(1).expand(n, m, d)\n",
        "    y = y.unsqueeze(0).expand(n, m, d)\n",
        "\n",
        "    return torch.pow(x - y, 2).sum(2)  # N x M\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeGcuLPnWc4D"
      },
      "source": [
        "dataset='Amazon_eletronics'\n",
        "adj, features, labels, degrees, class_list_train, class_list_valid, class_list_test, id_by_class = load_data(dataset)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idoqbMF2Wcr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e052f1bc-83db-4260-8aae-7de136ee8aa9"
      },
      "source": [
        "adj"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(indices=tensor([[    0,     2, 32910,  ..., 42316, 41512, 42317],\n",
              "                       [    0,     0,     0,  ..., 42316, 42317, 42317]]),\n",
              "       values=tensor([0.2500, 0.1890, 0.2236,  ..., 0.5000, 0.2673, 0.5000]),\n",
              "       size=(42318, 42318), nnz=129430, layout=torch.sparse_coo)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq3a4Ng1c5AZ",
        "outputId": "895ab2fb-bc3e-4f7e-95b9-fe1f2f6be02d"
      },
      "source": [
        "features"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws2JFH-0c8aH",
        "outputId": "b81d77a3-2290-4ab5-e60d-fc40f86bc6c0"
      },
      "source": [
        "labels.max()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(166)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BMOC2pZdJ_a",
        "outputId": "9d0c0f50-0e0c-4690-ba93-aa49f0d53183"
      },
      "source": [
        "degrees[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wpgr1IDdQuX",
        "outputId": "c9e240df-9850-4e3c-d825-c9053321053c"
      },
      "source": [
        "len(class_list_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Kb2S7OVdgbx",
        "outputId": "0fc83f57-edb0-4370-e931-09285a062577"
      },
      "source": [
        "len(class_list_valid),len(class_list_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SobgTNJadxGb"
      },
      "source": [
        "#id_by_class\n",
        "#چه آیدی هایی در هر کلاسی هستند"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwb2uCiuxc1h"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHTjJ5Dsxa1k"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class GPN_Encoder(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, dropout):\n",
        "        super(GPN_Encoder, self).__init__()\n",
        "\n",
        "        self.gc1 = GraphConvolution(nfeat, 2 * nhid)\n",
        "        self.gc2 = GraphConvolution(2 * nhid, nhid)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gc2(x, adj)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GPN_Valuator(nn.Module):\n",
        "    \"\"\"\n",
        "    For the sake of model efficiency, the current implementation is a little bit different from the original paper.\n",
        "    Note that you can still try different architectures for building the valuator network.\n",
        "    \"\"\"\n",
        "    def __init__(self, nfeat, nhid, dropout):\n",
        "        super(GPN_Valuator, self).__init__()\n",
        "        \n",
        "        self.gc1 = GraphConvolution(nfeat, 2 * nhid)\n",
        "        self.gc2 = GraphConvolution(2 * nhid, nhid)\n",
        "        self.fc3 = nn.Linear(nhid, 1)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu(self.gc2(x, adj))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMNDMpR-lqSc",
        "outputId": "3c271ff9-fcb8-496d-d7fe-6dad4274d8af"
      },
      "source": [
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--use_cuda', action='store_true', help='Disables CUDA training.')\n",
        "parser.add_argument('--seed', type=int, default=1234, help='Random seed.')\n",
        "parser.add_argument('--episodes', type=int, default=100,\n",
        "                    help='Number of episodes to train.')\n",
        "parser.add_argument('--lr', type=float, default=0.005,\n",
        "                    help='Initial learning rate.')\n",
        "parser.add_argument('--weight_decay', type=float, default=5e-4,\n",
        "                    help='Weight decay (L2 loss on parameters).')\n",
        "parser.add_argument('--hidden', type=int, default=16,\n",
        "                    help='Number of hidden units.')\n",
        "parser.add_argument('--dropout', type=float, default=0.5,\n",
        "                    help='Dropout rate (1 - keep probability).')\n",
        "\n",
        "\n",
        "parser.add_argument('--way', type=int, default=5, help='way.')\n",
        "parser.add_argument('--shot', type=int, default=5, help='shot.')\n",
        "parser.add_argument('--qry', type=int, help='k shot for query set', default=20)\n",
        "parser.add_argument('--dataset', default='Amazon_clothing', help='Dataset:Amazon_clothing/Amazon_eletronics/dblp')\n",
        "\n",
        "#args = parser.parse_args()\n",
        "args = parser.parse_known_args()[0]\n",
        "args.cuda = args.use_cuda and torch.cuda.is_available()\n",
        "\n",
        "random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "# Load data\n",
        "dataset = args.dataset\n",
        "adj, features, labels, degrees, class_list_train, class_list_valid, class_list_test, id_by_class = load_data(dataset)\n",
        "\n",
        "# Model and optimizer\n",
        "encoder = GPN_Encoder(nfeat=features.shape[1],\n",
        "            nhid=args.hidden,\n",
        "            dropout=args.dropout)\n",
        "\n",
        "\n",
        "scorer = GPN_Valuator(nfeat=features.shape[1],\n",
        "            nhid=args.hidden,\n",
        "            dropout=args.dropout)\n",
        "\n",
        "\n",
        "\n",
        "optimizer_encoder = optim.Adam(encoder.parameters(),\n",
        "                       lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "optimizer_scorer = optim.Adam(scorer.parameters(),\n",
        "                       lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "if args.cuda:\n",
        "    encoder.cuda()\n",
        "    scorer.cuda()\n",
        "    features = features.cuda()\n",
        "    adj = adj.cuda()\n",
        "    labels = labels.cuda()\n",
        "    degrees = degrees.cuda()\n",
        "\n",
        "def train(class_selected, id_support, id_query, n_way, k_shot):\n",
        "\n",
        "    encoder.train()\n",
        "    scorer.train()\n",
        "    optimizer_encoder.zero_grad()\n",
        "    optimizer_scorer.zero_grad()\n",
        "    embeddings = encoder(features, adj)\n",
        "    z_dim = embeddings.size()[1]\n",
        "    scores = scorer(features, adj)\n",
        "\n",
        "    # embedding lookup\n",
        "    support_embeddings = embeddings[id_support]\n",
        "    support_embeddings = support_embeddings.view([n_way, k_shot, z_dim])\n",
        "    query_embeddings = embeddings[id_query]\n",
        "\n",
        "    # node importance\n",
        "    support_degrees = torch.log(degrees[id_support].view([n_way, k_shot]))\n",
        "    support_scores = scores[id_support].view([n_way, k_shot])\n",
        "    support_scores = torch.sigmoid(support_degrees * support_scores).unsqueeze(-1)\n",
        "    support_scores = support_scores / torch.sum(support_scores, dim=1, keepdim=True)\n",
        "    support_embeddings = support_embeddings * support_scores\n",
        "\n",
        "    # compute loss\n",
        "    prototype_embeddings = support_embeddings.sum(1)\n",
        "    dists = euclidean_dist(query_embeddings, prototype_embeddings)\n",
        "    output = F.log_softmax(-dists, dim=1)\n",
        "\n",
        "    labels_new = torch.LongTensor([class_selected.index(i) for i in labels[id_query]])\n",
        "    if args.cuda:\n",
        "        labels_new = labels_new.cuda()\n",
        "    loss_train = F.nll_loss(output, labels_new)\n",
        "\n",
        "    loss_train.backward()\n",
        "    optimizer_encoder.step()\n",
        "    optimizer_scorer.step()\n",
        "\n",
        "    if args.cuda:\n",
        "        output = output.cpu().detach()\n",
        "        labels_new = labels_new.cpu().detach()\n",
        "    acc_train = accuracy(output, labels_new)\n",
        "    f1_train = f1(output, labels_new)\n",
        "\n",
        "    return acc_train, f1_train\n",
        "\n",
        "\n",
        "def test(class_selected, id_support, id_query, n_way, k_shot):\n",
        "    encoder.eval()\n",
        "    scorer.eval()\n",
        "    embeddings = encoder(features, adj)\n",
        "    z_dim = embeddings.size()[1]\n",
        "    scores = scorer(features, adj)\n",
        "\n",
        "    # embedding lookup\n",
        "    support_embeddings = embeddings[id_support]\n",
        "    support_embeddings = support_embeddings.view([n_way, k_shot, z_dim])\n",
        "    query_embeddings = embeddings[id_query]\n",
        "\n",
        "    # node importance\n",
        "    support_degrees = torch.log(degrees[id_support].view([n_way, k_shot]))\n",
        "    support_scores = scores[id_support].view([n_way, k_shot])\n",
        "    support_scores = torch.sigmoid(support_degrees * support_scores).unsqueeze(-1)\n",
        "    support_scores = support_scores / torch.sum(support_scores, dim=1, keepdim=True)\n",
        "    support_embeddings = support_embeddings * support_scores\n",
        "\n",
        "    # compute loss\n",
        "    prototype_embeddings = support_embeddings.sum(1)\n",
        "    dists = euclidean_dist(query_embeddings, prototype_embeddings)\n",
        "    output = F.log_softmax(-dists, dim=1)\n",
        "\n",
        "    labels_new = torch.LongTensor([class_selected.index(i) for i in labels[id_query]])\n",
        "    if args.cuda:\n",
        "        labels_new = labels_new.cuda()\n",
        "    loss_test = F.nll_loss(output, labels_new)\n",
        "\n",
        "    if args.cuda:\n",
        "        output = output.cpu().detach()\n",
        "        labels_new = labels_new.cpu().detach()\n",
        "    acc_test = accuracy(output, labels_new)\n",
        "    f1_test = f1(output, labels_new)\n",
        "\n",
        "    return acc_test, f1_test\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    n_way = args.way\n",
        "    k_shot = args.shot\n",
        "    n_query = args.qry\n",
        "    meta_test_num = 50\n",
        "    meta_valid_num = 50\n",
        "\n",
        "    # Sampling a pool of tasks for validation/testing\n",
        "    valid_pool = [task_generator(id_by_class, class_list_valid, n_way, k_shot, n_query) for i in range(meta_valid_num)]\n",
        "    test_pool = [task_generator(id_by_class, class_list_test, n_way, k_shot, n_query) for i in range(meta_test_num)]\n",
        "\n",
        "    # Train model\n",
        "    t_total = time.time()\n",
        "    meta_train_acc = []\n",
        "\n",
        "    for episode in range(args.episodes):\n",
        "        id_support, id_query, class_selected = \\\n",
        "            task_generator(id_by_class, class_list_train, n_way, k_shot, n_query)\n",
        "        acc_train, f1_train = train(class_selected, id_support, id_query, n_way, k_shot)\n",
        "        meta_train_acc.append(acc_train)\n",
        "        if episode > 0 and episode % 10 == 0:    \n",
        "            print(\"-------Episode {}-------\".format(episode))\n",
        "            print(\"Meta-Train_Accuracy: {}\".format(np.array(meta_train_acc).mean(axis=0)))\n",
        "\n",
        "            # validation\n",
        "            meta_test_acc = []\n",
        "            meta_test_f1 = []\n",
        "            for idx in range(meta_valid_num):\n",
        "                id_support, id_query, class_selected = valid_pool[idx]\n",
        "                acc_test, f1_test = test(class_selected, id_support, id_query, n_way, k_shot)\n",
        "                meta_test_acc.append(acc_test)\n",
        "                meta_test_f1.append(f1_test)\n",
        "            print(\"Meta-valid_Accuracy: {}, Meta-valid_F1: {}\".format(np.array(meta_test_acc).mean(axis=0),\n",
        "                                                                        np.array(meta_test_f1).mean(axis=0)))\n",
        "    # testing\n",
        "    meta_test_acc = []\n",
        "    meta_test_f1 = []\n",
        "    for idx in range(meta_test_num):\n",
        "        id_support, id_query, class_selected = test_pool[idx]\n",
        "        acc_test, f1_test = test(class_selected, id_support, id_query, n_way, k_shot)\n",
        "        meta_test_acc.append(acc_test)\n",
        "        meta_test_f1.append(f1_test)\n",
        "    print(\"Meta-Test_Accuracy: {}, Meta-Test_F1: {}\".format(np.array(meta_test_acc).mean(axis=0),\n",
        "                                                                        np.array(meta_test_f1).mean(axis=0)))\n",
        "\n",
        "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------Episode 10-------\n",
            "Meta-Train_Accuracy: 0.4736363636363636\n",
            "Meta-valid_Accuracy: 0.5948, Meta-valid_F1: 0.5765430960179537\n",
            "-------Episode 20-------\n",
            "Meta-Train_Accuracy: 0.4976190476190477\n",
            "Meta-valid_Accuracy: 0.6498, Meta-valid_F1: 0.6345667918172101\n",
            "-------Episode 30-------\n",
            "Meta-Train_Accuracy: 0.5219354838709678\n",
            "Meta-valid_Accuracy: 0.6711999999999999, Meta-valid_F1: 0.6594211518031463\n",
            "-------Episode 40-------\n",
            "Meta-Train_Accuracy: 0.5412195121951219\n",
            "Meta-valid_Accuracy: 0.6998000000000001, Meta-valid_F1: 0.6924089278207769\n",
            "-------Episode 50-------\n",
            "Meta-Train_Accuracy: 0.5652941176470588\n",
            "Meta-valid_Accuracy: 0.7058, Meta-valid_F1: 0.6976238900069154\n",
            "-------Episode 60-------\n",
            "Meta-Train_Accuracy: 0.5811475409836068\n",
            "Meta-valid_Accuracy: 0.7194000000000002, Meta-valid_F1: 0.7126993901781421\n",
            "-------Episode 70-------\n",
            "Meta-Train_Accuracy: 0.596338028169014\n",
            "Meta-valid_Accuracy: 0.7387999999999999, Meta-valid_F1: 0.7338105744665812\n",
            "-------Episode 80-------\n",
            "Meta-Train_Accuracy: 0.6088888888888889\n",
            "Meta-valid_Accuracy: 0.7277999999999999, Meta-valid_F1: 0.7225786789442605\n",
            "-------Episode 90-------\n",
            "Meta-Train_Accuracy: 0.6257142857142857\n",
            "Meta-valid_Accuracy: 0.7334, Meta-valid_F1: 0.7280660194778996\n",
            "Meta-Test_Accuracy: 0.7020000000000001, Meta-Test_F1: 0.6979223779929222\n",
            "Total time elapsed: 504.0305s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bRmlQfKo4HY"
      },
      "source": [
        "#test_pool\n",
        "#out put of task_generatr:\n",
        "#id_support,id_query, class_selected\n",
        "#برای هر کدام از تسک ها اعداد بصورت زیر هستند که حالا 50 بار تکرار میشه\n",
        "#class_selected=5=N_way\n",
        "#id_support=25=N_way * N_shot\n",
        "#id_query=100=N_way*20"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDvKS2qftXse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b75de2-5032-44eb-e225-fc3fd6876789"
      },
      "source": [
        "id_support, id_query, class_selected\n",
        "#واسه هر اپیزود"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 8832, 18701, 21463, 29797, 30053, 19328, 19926, 40280, 36563,\n",
              "         8675, 12691, 14877, 38058, 24731, 34848, 28256,  4702, 14570,\n",
              "        36527, 31766,  5295, 37524, 20639,  3857, 13750]),\n",
              " array([ 2274,  8683, 41309,  5300, 38968, 11385, 28668, 12956,   628,\n",
              "        12395, 40415, 36117, 11132,  1020,  8646, 26992, 29997, 37275,\n",
              "        34191, 13054, 34070, 30449, 27603,  8425, 12884, 31859,  5599,\n",
              "        15460,  9957,  6983, 14074, 33236, 17352, 36626, 18655, 18102,\n",
              "          190, 22796,  5596, 41964, 20894,  2269, 26060, 37560,  5016,\n",
              "         1499,  6300, 17548, 37476, 21751, 27307, 25863, 19787,   728,\n",
              "         3458, 11856, 37170,  9057,  7167,  6264, 30050, 23885,  4178,\n",
              "        15531, 18615, 40233, 36079,  8382, 35432, 19320, 17242, 23680,\n",
              "        38457, 11157,  8149, 40287, 21925, 24835, 29565, 11041, 14327,\n",
              "        17969, 39385,   200, 33939, 17672, 30163,  1340, 39845,  4610,\n",
              "        34342,  8957, 29521, 39080, 16366, 38045, 20744, 18760, 25412,\n",
              "         6212]),\n",
              " [157.0, 97.0, 49.0, 126.0, 117.0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jatJDH1Oxaqd"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}